#
# Wordless: CI - Azure Pipelines
#
# Copyright (C) 2018-2019  Ye Lei (叶磊)
#
# This source file is licensed under GNU GPLv3.
# For details, see: https://github.com/BLKSerene/Wordless/blob/master/LICENSE.txt
#
# All other rights reserved.
#

jobs:
# Windows
- job: "Windows"

  pool:
    vmImage: windows-2019

  steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.7.x' 
      architecture: 'x64'

  # Check Python version
  - script: |
      python --version
    displayName: 'Check Python version'

  # Install dependencies
  - script: |
      pip install --upgrade pip
      pip install -r requirements.txt
    displayName: 'Install dependencies'

  # Download spaCy models
  - script: |
      python -m spacy download nl_core_news_sm
      python -m spacy download en_core_web_sm
      python -m spacy download fr_core_news_sm
      python -m spacy download de_core_news_sm
      python -m spacy download el_core_news_sm
      python -m spacy download it_core_news_sm
      python -m spacy download lt_core_news_sm
      python -m spacy download nb_core_news_sm
      python -m spacy download pt_core_news_sm
      python -m spacy download es_core_news_sm
    displayName: 'Download spaCy models'

  # Download NLTK data
  - script: |
      python -m nltk.downloader averaged_perceptron_tagger
      python -m nltk.downloader averaged_perceptron_tagger_ru
      python -m nltk.downloader perluniprops
      python -m nltk.downloader punkt
      python -m nltk.downloader stopwords
      python -m nltk.downloader wordnet
    displayName: 'Download NLTK data'

  # Run tests - text processing
  - script: |
      cd src
      pytest wordless_tests/wordless_text/wordless_text_processing/test_sentence_tokenization.py
      pytest wordless_tests/wordless_text/wordless_text_processing/test_word_tokenization.py
      pytest wordless_tests/wordless_text/wordless_text_processing/test_word_detokenization.py
      pytest wordless_tests/wordless_text/wordless_text_processing/test_pos_tagging.py
      pytest wordless_tests/wordless_text/wordless_text_processing/test_lemmatization.py
      pytest wordless_tests/wordless_text/wordless_text_processing/test_stop_words.py
    displayName: 'Run tests - text processing'
  # Run tests - others
  - script: |
      cd src
      pytest --ignore=wordless_tests/test_init.py --ignore=wordless_tests/wordless_text/wordless_text_processing/
    displayName: 'Run tests - others'

# macOS
- job: "macOS"

  pool:
    vmImage: macOS-10.14

  steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.7.x' 

  # Check Python version
  - script: |
      python3 --version
    displayName: 'Check Python version'

  # Install dependencies
  - script: |
      pip3 install --upgrade pip
      pip3 install -r requirements.txt
    displayName: 'Install dependencies'

  # Download spaCy models
  - script: |
      python3 -m spacy download nl_core_news_sm
      python3 -m spacy download en_core_web_sm
      python3 -m spacy download fr_core_news_sm
      python3 -m spacy download de_core_news_sm
      python3 -m spacy download el_core_news_sm
      python3 -m spacy download it_core_news_sm
      python3 -m spacy download lt_core_news_sm
      python3 -m spacy download nb_core_news_sm
      python3 -m spacy download pt_core_news_sm
      python3 -m spacy download es_core_news_sm
    displayName: 'Download spaCy models'

  # Download NLTK data
  - script: |
      python3 -m nltk.downloader averaged_perceptron_tagger
      python3 -m nltk.downloader averaged_perceptron_tagger_ru
      python3 -m nltk.downloader perluniprops
      python3 -m nltk.downloader punkt
      python3 -m nltk.downloader stopwords
      python3 -m nltk.downloader wordnet
    displayName: 'Download NLTK data'

  # Run tests - text processing
  - script: |
      cd src
      pytest wordless_tests/wordless_text/wordless_text_processing/test_sentence_tokenization.py
      pytest wordless_tests/wordless_text/wordless_text_processing/test_word_tokenization.py
      pytest wordless_tests/wordless_text/wordless_text_processing/test_word_detokenization.py
      pytest wordless_tests/wordless_text/wordless_text_processing/test_pos_tagging.py
      pytest wordless_tests/wordless_text/wordless_text_processing/test_lemmatization.py
      pytest wordless_tests/wordless_text/wordless_text_processing/test_stop_words.py
    displayName: 'Run tests - text processing'
  # Run tests - others
  - script: |
      cd src
      pytest --ignore=wordless_tests/test_init.py --ignore=wordless_tests/wordless_text/wordless_text_processing/
    displayName: 'Run tests - others'

# Linux
- job: "Linux"

  pool:
    vmImage: ubuntu-16.04

  steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.7.x' 

  # Check Python version
  - script: |
      python3.7 --version
    displayName: 'Check Python version'

  # Install dependencies
  - script: |
      pip3.7 install --upgrade pip
      pip3.7 install -r requirements.txt
    displayName: 'Install dependencies'

  # Download spaCy models
  - script: |
      python3.7 -m spacy download nl_core_news_sm
      python3.7 -m spacy download en_core_web_sm
      python3.7 -m spacy download fr_core_news_sm
      python3.7 -m spacy download de_core_news_sm
      python3.7 -m spacy download el_core_news_sm
      python3.7 -m spacy download it_core_news_sm
      python3.7 -m spacy download lt_core_news_sm
      python3.7 -m spacy download nb_core_news_sm
      python3.7 -m spacy download pt_core_news_sm
      python3.7 -m spacy download es_core_news_sm
    displayName: 'Download spaCy models'

  # Download NLTK data
  - script: |
      python3.7 -m nltk.downloader averaged_perceptron_tagger
      python3.7 -m nltk.downloader averaged_perceptron_tagger_ru
      python3.7 -m nltk.downloader perluniprops
      python3.7 -m nltk.downloader punkt
      python3.7 -m nltk.downloader stopwords
      python3.7 -m nltk.downloader wordnet
    displayName: 'Download NLTK data'

  # Run tests - text processing
  - script: |
      cd src
      pytest wordless_tests/wordless_text/wordless_text_processing/test_sentence_tokenization.py
      pytest wordless_tests/wordless_text/wordless_text_processing/test_word_tokenization.py
      pytest wordless_tests/wordless_text/wordless_text_processing/test_word_detokenization.py
      pytest wordless_tests/wordless_text/wordless_text_processing/test_pos_tagging.py
      pytest wordless_tests/wordless_text/wordless_text_processing/test_lemmatization.py
      pytest wordless_tests/wordless_text/wordless_text_processing/test_stop_words.py
    displayName: 'Run tests - text processing'
  # Run tests - others
  - script: |
      cd src
      pytest --ignore=wordless_tests/test_init.py --ignore=wordless_tests/wordless_text/wordless_text_processing/
    displayName: 'Run tests - others'
